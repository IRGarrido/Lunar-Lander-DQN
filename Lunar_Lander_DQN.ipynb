{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IRGarrido/Lunar-Lander-DQN/blob/master/Lunar_Lander_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJHu3NYuUJn9"
      },
      "source": [
        "\n",
        "## Lunar Lander V3 - Deep Q-Learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install swig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE-jUdEpyAp8",
        "outputId": "ffff5843-0bdc-4218-a752-5e36f2c1c229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.11/dist-packages (4.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install gymnasium[box2d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6Fh_8aG87pR",
        "outputId": "d71db54e-38e0-4373-a7c2-6f56e419399f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yp_bkJ3fx8ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CnaDqSOUSDK"
      },
      "source": [
        "```\n",
        " pip install swig\n",
        " pip install gymnasium[box2d]\n",
        "```\n",
        "Imports necessários:\n",
        "\n",
        "\n",
        "*   OS\n",
        "*   Random\n",
        "*   Numpy\n",
        "*   Torch\n",
        "*   Gymnasium\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtOtA-a5TT2q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn # P/ Rede Neural\n",
        "import torch.optim as optim # Otimizador\n",
        "import torch.nn.functional as F # Funções de ativação, perda, convolução, etc (ReLU)\n",
        "import torch.autograd as autograd # Diferenciação automática (gradiente)\n",
        "from torch.autograd import Variable\n",
        "from collections import deque, namedtuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zowvpGAfTw8P",
        "outputId": "0d11274c-1f36-4fe6-df3e-4532d74b4783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State shape:  (8,)\n",
            "State size:  8\n",
            "Number of actions:  4\n",
            "Observation space:  Box([ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
            "  -0.         -0.       ], [ 2.5        2.5       10.        10.         6.2831855 10.\n",
            "  1.         1.       ], (8,), float32)\n"
          ]
        }
      ],
      "source": [
        "# Biblioteca Gymnasium\n",
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v3\", continuous=False, gravity=-10.0,\n",
        "               enable_wind=False, wind_power=15.0, turbulence_power=1.5)\n",
        "state_shape = env.observation_space.shape\n",
        "state_size = env.observation_space.shape[0]\n",
        "number_actions = env.action_space.n # 0 - Do Nothing, 1 - Fire left, 2 - Fire down, 3 - Fire right\n",
        "observation_space = env.observation_space\n",
        "print('State shape: ', state_shape)\n",
        "print('State size: ', state_size)\n",
        "print('Number of actions: ', number_actions)\n",
        "print('Observation space: ', observation_space)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaCPvqVJTyVH"
      },
      "outputs": [],
      "source": [
        "# Parâmetros de aprendizado\n",
        "learning_rate = 5e-4\n",
        "batch_size =100 #Tamanho da batela\n",
        "discount_factor = 0.99 # gamma\n",
        "replay_buffer_size = int(1e5) #Memory\n",
        "interpolation_parameter = 1e-3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rede Neural\n",
        "class Network(nn.Module):\n",
        "  def __init__(self,state_size,number_actions,seed=42):\n",
        "    super(Network, self).__init__()\n",
        "    self.seed = torch.manual_seed(seed)\n",
        "    self.fc1 = nn.Linear(state_size, 64)\n",
        "    self.fc2 = nn.Linear(64, 64) # 3 Camadas de neurônios totalmente conectadas\n",
        "    self.fc3 = nn.Linear(64, number_actions)\n",
        "\n",
        "\n",
        "  def forward(self, state):\n",
        "    x = self.fc1(state)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    q_values = self.fc3(x)\n",
        "    return q_values"
      ],
      "metadata": {
        "id": "8iUtccNoXKEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memória de aprendizado\n",
        "class ReplayMemory(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "\n",
        "    def push(self, event):\n",
        "        self.memory.append(event)\n",
        "        # Deleta a memória mais antiga se estiver cheio (capacidade).\n",
        "        if len(self.memory) > self.capacity:\n",
        "            del self.memory[0]\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        # Amostragem aleatória do tamanho do batch size\n",
        "        experiences = random.sample(self.memory, k = batch_size)\n",
        "        # Converte em tensores pytorch para serem processados pela rede neural\n",
        "        states = torch.from_numpy(np.vstack([e[0] for e in experiences if e is not None])).float().to(self.device)\n",
        "        actions = torch.from_numpy(np.vstack([e[1] for e in experiences if e is not None])).long().to(self.device)\n",
        "        rewards = torch.from_numpy(np.vstack([e[2] for e in experiences if e is not None])).float().to(self.device)\n",
        "        next_states = torch.from_numpy(np.vstack([e[3] for e in experiences if e is not None])).float().to(self.device)\n",
        "        dones = torch.from_numpy(np.vstack([e[4] for e in experiences if e is not None]).astype(np.uint8)).float().to(self.device)\n",
        "        return (states, actions, rewards, next_states, dones)"
      ],
      "metadata": {
        "id": "xe4jl_Rn180Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(): # Implementando o aprendizado DQN adaptado\n",
        "  def __init__(self,state_size,number_actions):\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.state_size =state_size\n",
        "    self.action_size = number_actions\n",
        "    self.memory = ReplayMemory(replay_buffer_size) # Memória\n",
        "    self.model = Network(state_size,number_actions).to(self.device) # Rede Neural\n",
        "    self.optmize = optim.Adam(self.model.parameters()) # Otimizador\n",
        "    self.target_network = Network(state_size,number_actions).to(self.device)\n",
        "    self.step=0\n",
        "\n",
        "  def step(self,state,action,reward,next_state,done):\n",
        "    self.memory.push((state,action,reward,next_state,done)) # Armazena no buffer\n",
        "    self.t_step = (self.t_step +1 )%4 # Atualiza os passos\n",
        "    if self.t_step == 0: # Verifica se é hora de treinar\n",
        "      if len(self.memory.memory) > batch_size:\n",
        "        experiences = self.memory.sample(batch_size)\n",
        "        self.learn(experiences,discount_factor)\n",
        "\n",
        "  def act(self, state, epsilon = 0.):\n",
        "    state = torch.from_numpy(state).float().unsqueeze(0).to(self.device) # Tensor\n",
        "    self.local_qnetwork.eval() # Modo de avaliação\n",
        "    with torch.no_grad():\n",
        "      action_values = self.local_qnetwork(state) # Cálculo de Q-values\n",
        "    self.local_qnetwork.train() # Treinamento\n",
        "    if random.random() > epsilon:\n",
        "      return np.argmax(action_values.cpu().data.numpy())\n",
        "    else:\n",
        "      return random.choice(np.arange(self.action_size)) # Escolhe uma ação com maior Q-value\n",
        "\n",
        "\n",
        "\n",
        "  def learn(self, experiences, discount_factor):\n",
        "    states, next_states, actions, rewards, dones = experiences # Extrai as memorias\n",
        "    next_q_targets = self.target_qnetwork(next_states).detach().max(1)[0].unsqueeze(1) # Calcula Q-values alvo\n",
        "    q_targets = rewards + discount_factor * next_q_targets * (1 - dones) # Equação de Bellman (Diferença Temporal)\n",
        "    q_expected = self.local_qnetwork(states).gather(1, actions)\n",
        "    loss = F.mse_loss(q_expected, q_targets) # Calcula perdas\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    self.soft_update(self.local_qnetwork, self.target_qnetwork, interpolation_parameter) # Propaga e atualiza a rede\n",
        "\n",
        "  def soft_update(self, local_model, target_model, interpolation_parameter):\n",
        "    for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "      target_param.data.copy_(interpolation_parameter * local_param.data + (1.0 - interpolation_parameter) * target_param.data)\n"
      ],
      "metadata": {
        "id": "DthgH9iF_pbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dqn = DQN(state_size,number_actions)"
      ],
      "metadata": {
        "id": "o2CkCMQHxsWc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}